# Enhanced Python Execution API - Detailed Metrics

## Overview

The Python execution API has been significantly enhanced to provide comprehensive resource usage metrics during code execution. This improvement addresses the need for better observability and performance monitoring of executed code.

## What's New

### Enhanced Execution Metrics

The API now returns detailed metrics about code execution, including:

#### üïê CPU Metrics
- **CPU User Time**: Time spent executing user code (in seconds)
- **CPU System Time**: Time spent in kernel/system calls (in seconds)  
- **CPU Percentage**: CPU usage percentage during execution
- **Total CPU Time**: Sum of user + system time (the processing time you requested!)

#### üíæ Memory Metrics
- **Memory Usage**: Current memory consumption (bytes)
- **Peak Memory**: Maximum memory usage during execution (bytes)
- **Memory Percentage**: Memory usage as percentage of container limit
- **Memory Limit**: Container memory limit (bytes)

#### üíø I/O Metrics
- **Block I/O Read**: Data read from disk (bytes)
- **Block I/O Write**: Data written to disk (bytes)
- **Network I/O RX**: Network data received (bytes)
- **Network I/O TX**: Network data transmitted (bytes)

#### üîß Process Metrics
- **Process Count**: Number of processes/threads created
- **Exit Code**: Process exit code (0 = success, non-zero = error)

#### ‚è±Ô∏è Timing Metrics
- **Execution Time**: Wall clock time for code execution (seconds)
- **More precise timing**: Based on actual execution rather than API overhead

## API Response Structure

### Before Enhancement
```json
{
  "success": true,
  "output": "Hello World",
  "error": null,
  "container_id": "abc123...",
  "execution_time": 1.234
}
```

### After Enhancement
```json
{
  "success": true,
  "output": "Hello World", 
  "error": null,
  "container_id": "abc123...",
  "container_name": "Unnamed",
  "execution_time": 1.234,
  "exit_code": 0,
  
  "cpu_user_time": 0.045,
  "cpu_system_time": 0.012,
  "cpu_percent": 15.7,
  
  "memory_usage": 23456789,
  "memory_peak": 45678901,
  "memory_percent": 4.5,
  "memory_limit": 536870912,
  
  "block_io_read": 4096,
  "block_io_write": 8192,
  "network_io_rx": 1024,
  "network_io_tx": 2048,
  
  "pids_count": 3
}
```

## Database Schema Updates

### New ExecutionLog Fields

The `execution_logs` table has been extended with the following columns:

```sql
-- CPU metrics
cpu_user_time REAL,
cpu_system_time REAL, 
cpu_percent REAL,

-- Memory metrics
memory_usage INTEGER,
memory_peak INTEGER,
memory_percent REAL,
memory_limit INTEGER,

-- I/O metrics
block_io_read INTEGER,
block_io_write INTEGER,
network_io_rx INTEGER,
network_io_tx INTEGER,

-- Process metrics
pids_count INTEGER,
exit_code INTEGER
```

## Implementation Details

### Metrics Collection Process

1. **Pre-execution**: Collect baseline container metrics
2. **Code Execution**: Run the Python code with timing
3. **Post-execution**: Collect final container metrics
4. **Differential Calculation**: Calculate execution-specific metrics
5. **Storage & Response**: Log to database and return to client

### Data Sources

- **Docker Stats API**: Primary source for container statistics
- **cgroup v2/v1 Files**: CPU time and memory peak data
- **Container Introspection**: Process information and exit codes

### Metric Calculation

- **Differential Metrics**: I/O and CPU time differences (execution-specific)
- **Snapshot Metrics**: Current memory usage, process count (final state)
- **Peak Metrics**: Maximum values observed during execution

## Usage Examples

### Simple CPU Test
```python
# Test CPU-intensive code
code = """
import math
result = sum(math.sqrt(i) for i in range(100000))
print(f"Result: {result}")
"""

# API response will show:
# - cpu_user_time: Time spent in computation
# - cpu_system_time: Minimal (pure computation)
# - memory_usage: Small (just numbers)
```

### Memory Test  
```python
# Test memory allocation
code = """
big_list = list(range(1000000))
print(f"Created list of {len(big_list)} items")
"""

# API response will show:
# - memory_usage: Current memory after allocation
# - memory_peak: Maximum memory during execution
# - memory_percent: Percentage of container limit
```

### I/O Test
```python
# Test file operations
code = """
import tempfile
with tempfile.NamedTemporaryFile(mode='w', delete=False) as f:
    f.write("x" * 10000)
    print(f"Wrote to {f.name}")
"""

# API response will show:
# - block_io_write: Bytes written to disk
# - block_io_read: Any data read from disk
```

## Migration Guide

### Running the Migration

```bash
python migrate_database.py
```

This will:
- Check if new columns exist
- Add missing columns with appropriate data types
- Preserve existing data
- Print progress information

### Backward Compatibility

- Existing API calls will continue to work
- New fields are optional in responses (may be null)
- Old execution logs will have null values for new metrics
- No breaking changes to existing endpoints

## Benefits

### For Developers
- **Performance Optimization**: Identify CPU, memory, and I/O bottlenecks
- **Resource Planning**: Understand actual resource requirements
- **Debugging**: Better error diagnosis with exit codes and resource usage
- **Monitoring**: Track resource usage trends over time

### For Operations
- **Capacity Planning**: Data-driven container sizing decisions
- **Cost Optimization**: Right-size resources based on actual usage
- **SLA Monitoring**: Track execution performance metrics
- **Alerting**: Set up alerts based on resource thresholds

## Testing

Run the comprehensive test suite:

```bash
python test_enhanced_execution.py
```

This will test:
- CPU-bound computations
- Memory-intensive operations  
- File I/O operations
- Package-dependent code (NumPy example)

## Performance Impact

- **Minimal Overhead**: Metrics collection adds ~100-200ms per execution
- **Efficient Collection**: Uses Docker's built-in stats APIs
- **Async Processing**: Metrics don't block code execution
- **Graceful Degradation**: Missing metrics don't break execution

## Troubleshooting

### Common Issues

1. **Missing CPU Time**: Some containers may not expose cgroup files
   - **Solution**: Metrics will show null, execution continues normally

2. **Docker Stats Not Available**: Older Docker versions may not support JSON stats
   - **Solution**: Basic metrics still collected, advanced metrics may be null

3. **Permission Issues**: Container may not have access to cgroup files
   - **Solution**: Run containers with appropriate privileges or accept limited metrics

### Debug Information

Check the console output for warnings about metric collection failures. The system is designed to work even when some metrics are unavailable.

## Future Enhancements

Potential future improvements:
- **Real-time Metrics**: Streaming metrics during long-running executions
- **GPU Metrics**: For ML workloads using GPU resources
- **Network Breakdown**: More detailed network usage analysis
- **Custom Metrics**: User-defined metrics collection
- **Historical Analysis**: Trend analysis and performance regression detection

## Questions or Issues?

The enhanced execution API provides comprehensive insights into code execution performance. All existing functionality remains unchanged while providing powerful new observability features. 